# yaml-language-server: $schema=https://raw.githubusercontent.com/datreeio/CRDs-catalog/refs/heads/main/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: alloy
  namespace: monitoring
spec:
  chart:
    spec:
      chart: alloy
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: grafana
      version: 1.x.x
  dependsOn:
    - name: kube-prometheus-stack
      namespace: monitoring
  install:
    crds: Create
  interval: 1m
  upgrade:
    crds: CreateReplace
  values:
    crds:
      create: true
    alloy:
      configMap:
        create: true
        # Content to assign to the new ConfigMap. This is passed into `tpl`
        # allowing for templating from values.
        # Ref:
        #   - https://grafana.com/docs/alloy/latest/reference/components/loki/loki.source.journal/
        #   - https://grafana.com/docs/alloy/latest/collect/logs-in-kubernetes/
        content: |
          loki.write "default" {
            endpoint {
              url = "http://monitoring-loki-gateway.monitoring.svc.cluster.local/loki/api/v1/push"
            }
          }

          loki.relabel "journal" {
            forward_to = []
            rule {
              source_labels = ["__journal__systemd_unit"]
              target_label  = "unit"
            }
          }

          // Collect systemd journal logs
          loki.source.journal "node_journal_logs" {
            labels = {
              job       = "node/journal",
              node_name = sys.env("HOSTNAME"),
              cluster   = "homelab",
            }
            relabel_rules = loki.relabel.journal.rules
            forward_to = [loki.write.default.receiver]
          }

          // discovery.kubernetes allows you to find scrape targets from
          // Kubernetes resources. It watches cluster state and ensures targets
          // are continually synced with what is currently running in your
          // cluster.
          discovery.kubernetes "pod" {
            role = "pod"
            // Restrict to pods on the node to reduce cpu & memory usage
            selectors {
              role = "pod"
              field = "spec.nodeName=" + coalesce(sys.env("HOSTNAME"), constants.hostname)
            }
          }

          // discovery.relabel rewrites the label set of the input targets by
          // applying one or more relabeling rules. If no rules are defined, then
          // the input targets are exported as-is.
          discovery.relabel "pod_logs" {
            targets = discovery.kubernetes.pod.targets

            // Label creation - "namespace" field from "__meta_kubernetes_namespace"
            rule {
              source_labels = ["__meta_kubernetes_namespace"]
              action = "replace"
              target_label = "namespace"
            }

            // Label creation - "pod" field from "__meta_kubernetes_pod_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_name"]
              action = "replace"
              target_label = "pod"
            }

            // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "container"
            }

            // Label creation - "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
            rule {
              source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
              action = "replace"
              target_label = "app"
            }

            // Label creation - "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
            // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
            rule {
              source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "job"
              separator = "/"
              replacement = "$1"
            }

            // Label creation - "__path__" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
            // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
            rule {
              source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
              action = "replace"
              target_label = "__path__"
              separator = "/"
              replacement = "/var/log/pods/*$1/*.log"
            }

            // Label creation - "container_runtime" field from "__meta_kubernetes_pod_container_id"
            rule {
              source_labels = ["__meta_kubernetes_pod_container_id"]
              action = "replace"
              target_label = "container_runtime"
              regex = "^(\\S+):\\/\\/.+$"
              replacement = "$1"
            }
          }

          // loki.source.kubernetes tails logs from Kubernetes containers using
          // the Kubernetes API.
          loki.source.kubernetes "pod_logs" {
            targets    = discovery.relabel.pod_logs.output
            forward_to = [loki.process.pod_logs.receiver]
          }

          // loki.process receives log entries from other Loki components, applies
          // one or more processing stages, and forwards the results to the list
          // of receivers in the component's arguments.
          loki.process "pod_logs" {
            stage.static_labels {
                values = {
                  cluster = "homelab",
                }
            }

            forward_to = [loki.write.default.receiver]
          }

          // loki.source.kubernetes_events tails events from the Kubernetes API
          // and converts them into log lines to forward to other Loki components.
          loki.source.kubernetes_events "cluster_events" {
            job_name   = "integrations/kubernetes/eventhandler"
            log_format = "logfmt"
            forward_to = [
              loki.process.cluster_events.receiver,
            ]
          }

          // loki.process receives log entries from other loki components, applies
          // one or more processing stages, and forwards the results to the list
          // of receivers in the component's arguments.
          loki.process "cluster_events" {
            forward_to = [loki.write.default.receiver]

            stage.static_labels {
              values = {
                cluster = "homelab",
              }
            }

            stage.labels {
              values = {
                kubernetes_cluster_events = "job",
              }
            }
          }
      # Enables sending Grafana Labs anonymous usage stats to help improve
      # Grafana Alloy.
      enableReporting: false
      mounts:
        # Mount /var/log from the host into the container for log collection.
        varlog: true
        # Mount /var/lib/docker/containers from the host into the container
        # for log collection.
        dockercontainers: false
      # Resource requests and limits to apply to the Grafana Alloy container.
      resources:
        requests:
          cpu: 80m
          memory: 100Mi
        limits:
          cpu: 100m
          memory: 150Mi
    controller:
      type: daemonset
    serviceMonitor:
      enabled: true
      additionalLabels:
        release: monitoring-kube-prometheus-stack
